{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71f75a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader, WebBaseLoader, PyPDFLoader\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa9a01f",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb696b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content='Today, I want to talk about something that seems simple but defines the direction of our livesâ€”discipline. Discipline is not just about rules or restrictions; it is about self-control, consistency, and the ability to choose long-term growth over short-term comfort.\\n\\nWhen we practice discipline, we train ourselves to stay focused, to work hard even when no one is watching, and to keep going when things get difficult. It is discipline that turns talent into success and dreams into reality.\\n\\nIn life, we cannot control every outcome, but we can control our habits and our actions. And when discipline becomes a habit, success is no longer a question of if, but when.\\n\\nSo, letâ€™s remind ourselves daily: freedom and success are not found in avoiding disciplineâ€”they are achieved through it.\\n\\nThank you.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = TextLoader(\"speech.txt\")\n",
    "text_docs = loader.load()\n",
    "text_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6e42302",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "os.environ[\"XAI_API_KEY\"] = os.getenv(\"XAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59c06e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Web based loader\n",
    "loader = WebBaseLoader(\n",
    "    web_path=\"https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/\", \n",
    "    bs_kwargs=dict(parse_only = bs4.SoupStrainer(\n",
    "        class_ = (\"md-container\", \"md-header\")\n",
    "    )),\n",
    "    )\n",
    "\n",
    "text_docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c1b3b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PDF reader\n",
    "loader = PyPDFLoader('lec_6.pdf')\n",
    "text_docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd33fd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n",
    "docs = text_splitter.split_documents(text_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e9ec86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vector Embeddings & store\n",
    "\n",
    "db = Chroma.from_documents(docs[:20], OpenAIEmbeddings())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d7992e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'creationdate': '2024-03-19T21:25:11-05:00', 'producer': 'Microsoft: Print To PDF', 'creator': 'PyPDF', 'page_label': '3', 'page': 2, 'title': 'Microsoft PowerPoint - 3_Self_Attention_Transformer', 'total_pages': 56, 'moddate': '2024-03-19T21:25:11-05:00', 'source': 'lec_6.pdf', 'author': 'Shaurya Tripathi'}, page_content='3/19/2024\\n3\\nIssues with Recurrent Attention•Scalability issues•Performance degrades as the distance between words increases•Parallelization limitations•Recurrent processes lacks ability to be parallelized•Memory constraints•RNNs have limited memory and struggle with long-range dependencies•Diluted impact of earlier elements on output as sequence progresses•Potential solution: decouple attention from RNNs•How? Separate the attention mechanism into smaller, self-contained components5Slide Credit : https://cs.uwaterloo.ca/~wenhuche/teaching/cs886/\\nSelf -ATTENTION5\\n6'),\n",
       " Document(metadata={'creator': 'PyPDF', 'source': 'lec_6.pdf', 'creationdate': '2024-03-19T21:25:11-05:00', 'page': 0, 'author': 'Shaurya Tripathi', 'title': 'Microsoft PowerPoint - 3_Self_Attention_Transformer', 'page_label': '1', 'producer': 'Microsoft: Print To PDF', 'moddate': '2024-03-19T21:25:11-05:00', 'total_pages': 56}, page_content='3/19/2024\\n1\\nRNN –Issues\\nhttps://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/slides/cs224n-2021-lecture09-transformers.pdf\\n1\\n2')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"RNN\"\n",
    "result = db.similarity_search(query, k=2)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9aab64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
