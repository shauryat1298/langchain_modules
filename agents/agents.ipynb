{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a4eaff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.tools import WikipediaQueryRun, ArxivQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f34d8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a31fb8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "wiki = WikipediaQueryRun(api_wrapper=wiki_wrapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfedda62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001FB9FD2E9D0>, search_kwargs={})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(\"https://docs.langchain.com/langsmith/home\")\n",
    "docs = loader.load()\n",
    "doc_splits = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap = 200).split_documents(docs)\n",
    "vector_db = FAISS.from_documents(doc_splits, OpenAIEmbeddings())\n",
    "retriever = vector_db.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec8f9aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_tool = create_retriever_tool(retriever, \"langsmith_search\",\n",
    "                                       \"Search for information about LangSmith, for any langsmith search you must use this tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf7d0189",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_wrapper = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "arxiv = ArxivQueryRun(api_wrapper=arxiv_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "209ce9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\shaur\\\\Desktop\\\\Learnings\\\\Langchain\\\\lang_env\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " Tool(name='langsmith_search', description='Search for information about LangSmith, for any langsmith search you must use this tool', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001FB9E5F2F20>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001FB9FD2E9D0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001FB9E638400>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001FB9FD2E9D0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [wiki, arxiv, retrieval_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc0e6682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-5-nano\", temperature=0)\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd5ea7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001FBF5EF28E0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001FBF5EF28E0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001FBEE77B510>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001FBEE742490>, root_client=<openai.OpenAI object at 0x000001FBEE77A950>, root_async_client=<openai.AsyncOpenAI object at 0x000001FBEE742F10>, model_name='gpt-5-nano', model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith_search', 'description': 'Search for information about LangSmith, for any langsmith search you must use this tool', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\shaur\\\\Desktop\\\\Learnings\\\\Langchain\\\\lang_env\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200)), Tool(name='langsmith_search', description='Search for information about LangSmith, for any langsmith search you must use this tool', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001FB9E5F2F20>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001FB9FD2E9D0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001FB9E638400>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001FB9FD2E9D0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Agents\n",
    "agent = create_openai_tools_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "\n",
    "## Agent Executor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91861344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'LangSmith'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLangSmith is framework agnostic — you can use it with or without LangChain’s open source frameworks langchain and langgraph.\n",
      "\n",
      "Get started with LangSmith - Docs by LangChainOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KLangSmithPlatform for LLM observability and evaluationOverviewQuickstartsTrace an applicationEvaluate an applicationTest promptsAPI & SDKsAPI referencePython SDKJS/TS SDKPricingPlansPricing FAQOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KGitHubForumForumSearch...NavigationGet started with LangSmithGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGitHubForumGet started with LangSmithCopy pageCopy pageLangSmith is a platform for building production-grade LLM applications. Monitor and evaluate your application, so you can ship quickly and with confidence.\n",
      "\n",
      "Start tracingGain visibility into each step your application takes when handling a request to debug faster.Learn moreEvaluate your applicationMeasure quality of your applications over time to build more reliable AI applications.Learn moreTest your promptsIterate on prompts, with automatic version control and collaboration features.Learn moreSet up your workspaceSet up your workspace, configure admin settings, and invite your team to collaborate.Learn moreWas this page helpful?YesNoTrace an applicationAssistantResponses are generated using AI and may contain mistakes.Docs by LangChain home pagegithubxlinkedinyoutubeResourcesChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by Mintlify\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith is a platform (by LangChain) for building production-grade LLM applications. It’s framework-agnostic, so you can use it with or without LangChain’s open-source frameworks like LangChain or LangGraph. Its main goal is to help you monitor, evaluate, and iterate on your AI applications with confidence.\n",
      "\n",
      "Key capabilities\n",
      "- Tracing: Get visibility into each step of a request to debug faster.\n",
      "- Evaluation: Measure quality over time to ship more reliable AI apps.\n",
      "- Prompt testing: Iterate on prompts with version control and collaboration features.\n",
      "- Versioned prompts: Automatic versioning so you can track changes and compare prompts.\n",
      "- Collaboration and admin: Set up workspaces, invite teammates, and manage access.\n",
      "- Self-hosting: Options to self-host for more control.\n",
      "- SDKs and integrations: API and SDKs for Python and JS/TS; works with or without LangChain/LangGraph.\n",
      "\n",
      "What to do next\n",
      "- Start with the LangSmith docs to set up a workspace and instrument your app.\n",
      "- Trace a few requests to see how data flows and where to improve.\n",
      "- Use the evaluation tools to compare prompts/models over time.\n",
      "\n",
      "If you’d like, I can pull up specific docs, show a quick setup example, or explain pricing and hosting options.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about langsmith',\n",
       " 'output': 'LangSmith is a platform (by LangChain) for building production-grade LLM applications. It’s framework-agnostic, so you can use it with or without LangChain’s open-source frameworks like LangChain or LangGraph. Its main goal is to help you monitor, evaluate, and iterate on your AI applications with confidence.\\n\\nKey capabilities\\n- Tracing: Get visibility into each step of a request to debug faster.\\n- Evaluation: Measure quality over time to ship more reliable AI apps.\\n- Prompt testing: Iterate on prompts with version control and collaboration features.\\n- Versioned prompts: Automatic versioning so you can track changes and compare prompts.\\n- Collaboration and admin: Set up workspaces, invite teammates, and manage access.\\n- Self-hosting: Options to self-host for more control.\\n- SDKs and integrations: API and SDKs for Python and JS/TS; works with or without LangChain/LangGraph.\\n\\nWhat to do next\\n- Start with the LangSmith docs to set up a workspace and instrument your app.\\n- Trace a few requests to see how data flows and where to improve.\\n- Use the evaluation tools to compare prompts/models over time.\\n\\nIf you’d like, I can pull up specific docs, show a quick setup example, or explain pricing and hosting options.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"Tell me about langsmith\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "533926d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHere’s a concise overview of machine learning (ML) and how it fits together.\n",
      "\n",
      "What is machine learning?\n",
      "- ML is the practice of building systems that learn from data to make predictions or decisions, rather than following explicit, hand-written rules.\n",
      "\n",
      "Core types of ML\n",
      "- Supervised learning: learn from labeled data to predict a target. Tasks include:\n",
      "  - Classification (e.g., spam vs. not spam)\n",
      "  - Regression (e.g., predicting house prices)\n",
      "- Unsupervised learning: learn from unlabeled data to find structure or patterns.\n",
      "  - Clustering (e.g., customer segmentation)\n",
      "  - Dimensionality reduction (e.g., reducing features for visualization)\n",
      "- Semi-supervised learning: uses mostly unlabeled data with a small amount of labeled data.\n",
      "- Reinforcement learning: an agent learns by interacting with an environment and maximizing cumulative rewards (common in robotics, games).\n",
      "\n",
      "How ML works at a high level\n",
      "1. Define the problem and objective (what you want to predict or optimize).\n",
      "2. Collect and prepare data (cleaning, handling missing values, encoding categories).\n",
      "3. Split data into training, validation, and test sets.\n",
      "4. Choose a model/algorithm and train it on the training data.\n",
      "5. Evaluate on validation data; tune hyperparameters.\n",
      "6. Test the final model on unseen data; deploy if satisfactory.\n",
      "7. Monitor in production and retrain as data drifts.\n",
      "\n",
      "Common algorithms and where they’re used\n",
      "- Linear models: linear regression (predict continuous values), logistic regression (probabilities/classification).\n",
      "- Tree-based methods: decision trees, random forests, gradient boosting (great for tabular data).\n",
      "- Support vector machines (SVM): effective in high dimensions for classification.\n",
      "- Nearest neighbors (k-NN): simple, used for small datasets.\n",
      "- Neural networks:\n",
      "  - Feedforward networks: general-purpose function approximators.\n",
      "  - Convolutional neural networks (CNNs): images and grids.\n",
      "  - Recurrent/Transformer models: language, time-series, sequential data; transformers power many modern NLP systems.\n",
      "- Unsupervised techniques:\n",
      "  - K-means, DBSCAN (clustering)\n",
      "  - PCA, t-SNE (dimensionality reduction)\n",
      "\n",
      "Key concepts and best practices\n",
      "- Training vs. validation vs. test: helps detect overfitting and measure generalization.\n",
      "- Overfitting vs. underfitting: balance model complexity with data availability.\n",
      "- Features and preprocessing: scaling/normalization, one-hot encoding for categorical data, handling missing values.\n",
      "- Evaluation metrics:\n",
      "  - Classification: accuracy, precision, recall, F1, ROC-AUC\n",
      "  - Regression: RMSE, MAE, R^2\n",
      "  - Clustering: silhouette score\n",
      "- Data leakage: ensure information from the test/validation set isn’t used to train the model.\n",
      "- Model deployment lifecycle: versioned models, monitoring for drift, A/B testing, and reproducibility.\n",
      "\n",
      "Practical applications\n",
      "- Computer vision: image classification, object detection, medical imaging.\n",
      "- Natural language processing: text classification, translation, chatbots, summarization.\n",
      "- Time-series forecasting: stock prices, demand forecasting.\n",
      "- Recommender systems: suggesting products or content.\n",
      "- Healthcare, finance, engineering: risk scoring, anomaly detection, predictive maintenance.\n",
      "\n",
      "Getting started (learning path for beginners)\n",
      "- Learn the basics:\n",
      "  - Concepts: supervised vs unsupervised learning, simple algorithms, evaluation metrics.\n",
      "  - Tools: Python, NumPy, pandas, scikit-learn for starters.\n",
      "- Hands-on practice:\n",
      "  - Datasets: Iris (small), Titanic, MNIST (image-ish), housing prices, Iris is great for a first classifier; Titanic for binary classification with some data wrangling.\n",
      "  - Follow a beginner-friendly course or book (e.g., introductory ML course, Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow).\n",
      "- Expand progressively:\n",
      "  - Deep learning basics with PyTorch or TensorFlow for images/text.\n",
      "  - Practice projects in your domain of interest.\n",
      "- Ethical and practical considerations:\n",
      "  - Be mindful of data quality, bias, interpretability, and privacy.\n",
      "  - Consider deployment concerns: latency, scalability, monitoring, and reproducibility.\n",
      "\n",
      "If you’d like, tell me your background, what domain you’re interested in, and how deep you want to go. I can tailor a beginner-friendly learning plan, suggest specific datasets, or give you a small starter example in Python.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about machine learning',\n",
       " 'output': 'Here’s a concise overview of machine learning (ML) and how it fits together.\\n\\nWhat is machine learning?\\n- ML is the practice of building systems that learn from data to make predictions or decisions, rather than following explicit, hand-written rules.\\n\\nCore types of ML\\n- Supervised learning: learn from labeled data to predict a target. Tasks include:\\n  - Classification (e.g., spam vs. not spam)\\n  - Regression (e.g., predicting house prices)\\n- Unsupervised learning: learn from unlabeled data to find structure or patterns.\\n  - Clustering (e.g., customer segmentation)\\n  - Dimensionality reduction (e.g., reducing features for visualization)\\n- Semi-supervised learning: uses mostly unlabeled data with a small amount of labeled data.\\n- Reinforcement learning: an agent learns by interacting with an environment and maximizing cumulative rewards (common in robotics, games).\\n\\nHow ML works at a high level\\n1. Define the problem and objective (what you want to predict or optimize).\\n2. Collect and prepare data (cleaning, handling missing values, encoding categories).\\n3. Split data into training, validation, and test sets.\\n4. Choose a model/algorithm and train it on the training data.\\n5. Evaluate on validation data; tune hyperparameters.\\n6. Test the final model on unseen data; deploy if satisfactory.\\n7. Monitor in production and retrain as data drifts.\\n\\nCommon algorithms and where they’re used\\n- Linear models: linear regression (predict continuous values), logistic regression (probabilities/classification).\\n- Tree-based methods: decision trees, random forests, gradient boosting (great for tabular data).\\n- Support vector machines (SVM): effective in high dimensions for classification.\\n- Nearest neighbors (k-NN): simple, used for small datasets.\\n- Neural networks:\\n  - Feedforward networks: general-purpose function approximators.\\n  - Convolutional neural networks (CNNs): images and grids.\\n  - Recurrent/Transformer models: language, time-series, sequential data; transformers power many modern NLP systems.\\n- Unsupervised techniques:\\n  - K-means, DBSCAN (clustering)\\n  - PCA, t-SNE (dimensionality reduction)\\n\\nKey concepts and best practices\\n- Training vs. validation vs. test: helps detect overfitting and measure generalization.\\n- Overfitting vs. underfitting: balance model complexity with data availability.\\n- Features and preprocessing: scaling/normalization, one-hot encoding for categorical data, handling missing values.\\n- Evaluation metrics:\\n  - Classification: accuracy, precision, recall, F1, ROC-AUC\\n  - Regression: RMSE, MAE, R^2\\n  - Clustering: silhouette score\\n- Data leakage: ensure information from the test/validation set isn’t used to train the model.\\n- Model deployment lifecycle: versioned models, monitoring for drift, A/B testing, and reproducibility.\\n\\nPractical applications\\n- Computer vision: image classification, object detection, medical imaging.\\n- Natural language processing: text classification, translation, chatbots, summarization.\\n- Time-series forecasting: stock prices, demand forecasting.\\n- Recommender systems: suggesting products or content.\\n- Healthcare, finance, engineering: risk scoring, anomaly detection, predictive maintenance.\\n\\nGetting started (learning path for beginners)\\n- Learn the basics:\\n  - Concepts: supervised vs unsupervised learning, simple algorithms, evaluation metrics.\\n  - Tools: Python, NumPy, pandas, scikit-learn for starters.\\n- Hands-on practice:\\n  - Datasets: Iris (small), Titanic, MNIST (image-ish), housing prices, Iris is great for a first classifier; Titanic for binary classification with some data wrangling.\\n  - Follow a beginner-friendly course or book (e.g., introductory ML course, Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow).\\n- Expand progressively:\\n  - Deep learning basics with PyTorch or TensorFlow for images/text.\\n  - Practice projects in your domain of interest.\\n- Ethical and practical considerations:\\n  - Be mindful of data quality, bias, interpretability, and privacy.\\n  - Consider deployment concerns: latency, scalability, monitoring, and reproducibility.\\n\\nIf you’d like, tell me your background, what domain you’re interested in, and how deep you want to go. I can tailor a beginner-friendly learning plan, suggest specific datasets, or give you a small starter example in Python.'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"Tell me about machine learning\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff85ed11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env (3.11.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
