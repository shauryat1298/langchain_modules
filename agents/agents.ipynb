{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a4eaff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.tools import WikipediaQueryRun, ArxivQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f34d8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a31fb8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: Artificial intelligence\n",
      "Summary: Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasonin\n"
     ]
    }
   ],
   "source": [
    "wiki_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "wiki = WikipediaQueryRun(api_wrapper=wiki_wrapper)\n",
    "print(wiki.invoke(\"AI\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfedda62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000020CBFB699D0>, search_kwargs={})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(\"https://docs.langchain.com/langsmith/home\")\n",
    "docs = loader.load()\n",
    "doc_splits = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap = 200).split_documents(docs)\n",
    "vector_db = FAISS.from_documents(doc_splits, OpenAIEmbeddings())\n",
    "retriever = vector_db.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec8f9aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_tool = create_retriever_tool(retriever, \"langsmith_search\",\n",
    "                                       \"Search for information about LangSmith, for any langsmith search you must use this tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf7d0189",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_wrapper = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "arxiv = ArxivQueryRun(api_wrapper=arxiv_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "209ce9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\shaur\\\\Desktop\\\\Learnings\\\\Langchain\\\\lang_env\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " Tool(name='langsmith_search', description='Search for information about LangSmith, for any langsmith search you must use this tool', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000020CBDF4B7E0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000020CBFB699D0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000020CBDFC4D60>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000020CBFB699D0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [wiki, arxiv, retrieval_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc0e6682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-5-nano\", temperature=0)\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd5ea7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000020C9591FE20>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000020C9591FE20>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000020D54D6C910>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000020D54D6ECD0>, root_client=<openai.OpenAI object at 0x0000020D548CC850>, root_async_client=<openai.AsyncOpenAI object at 0x0000020D54D6C890>, model_name='gpt-5-nano', model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith_search', 'description': 'Search for information about LangSmith, for any langsmith search you must use this tool', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\shaur\\\\Desktop\\\\Learnings\\\\Langchain\\\\lang_env\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200)), Tool(name='langsmith_search', description='Search for information about LangSmith, for any langsmith search you must use this tool', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000020CBDF4B7E0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000020CBFB699D0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000020CBDFC4D60>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000020CBFB699D0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Agents\n",
    "agent = create_openai_tools_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "\n",
    "## Agent Executor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91861344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'LangSmith LangChain'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLangSmith is framework agnostic — you can use it with or without LangChain’s open source frameworks langchain and langgraph.\n",
      "\n",
      "Get started with LangSmith - Docs by LangChainOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KLangSmithPlatform for LLM observability and evaluationOverviewQuickstartsTrace an applicationEvaluate an applicationTest promptsAPI & SDKsAPI referencePython SDKJS/TS SDKPricingPlansPricing FAQOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KGitHubForumForumSearch...NavigationGet started with LangSmithGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGitHubForumGet started with LangSmithCopy pageCopy pageLangSmith is a platform for building production-grade LLM applications. Monitor and evaluate your application, so you can ship quickly and with confidence.\n",
      "\n",
      "Start tracingGain visibility into each step your application takes when handling a request to debug faster.Learn moreEvaluate your applicationMeasure quality of your applications over time to build more reliable AI applications.Learn moreTest your promptsIterate on prompts, with automatic version control and collaboration features.Learn moreSet up your workspaceSet up your workspace, configure admin settings, and invite your team to collaborate.Learn moreWas this page helpful?YesNoTrace an applicationAssistantResponses are generated using AI and may contain mistakes.Docs by LangChain home pagegithubxlinkedinyoutubeResourcesChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by Mintlify\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith is a platform for building and operating production-grade LLM applications. It focuses on observability, evaluation, and collaboration to help you ship faster and more reliably.\n",
      "\n",
      "Key ideas\n",
      "- Framework-agnostic: can be used with LangChain and its ecosystem, but also works with non-LangChain setups. It’s designed to be platform-agnostic.\n",
      "- Observability: trace and gain visibility into each step of a request to debug faster.\n",
      "- Evaluation: measure quality over time, track metrics, and compare changes as you iterate.\n",
      "- Prompt testing and versioning: test prompts, manage prompt versions, and collaborate with your team.\n",
      "- Collaboration and governance: set up a workspace, configure admin settings, invite teammates, and implement access controls.\n",
      "- Self-hosting option: you can self-host LangSmith if you prefer or need to run it on your own infrastructure.\n",
      "- SDKs and APIs: available Python and JavaScript/TypeScript SDKs (with a REST API) to instrument and interact with LangSmith from your app.\n",
      "\n",
      "Typical workflow\n",
      "- Trace an application: instrument your code so LangSmith records each step of the LLM request.\n",
      "- Evaluate and monitor: view metrics and traces to understand quality and performance over time.\n",
      "- Test prompts: iterate on prompts with version control and collaboration features.\n",
      "- Set up a workspace: manage users, roles, and permissions; optionally self-host.\n",
      "\n",
      "Who it’s for\n",
      "- AI/ML engineers, data scientists, and product teams building production LLM apps who need reliable observability, prompt management, and debuggability.\n",
      "\n",
      "If you’d like, I can:\n",
      "- walk you through getting started (tools, code snippets, and a minimal trace example),\n",
      "- point you to the official docs for setup and SDK usage,\n",
      "- or help compare LangSmith with other observability tools.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about langsmith',\n",
       " 'output': 'LangSmith is a platform for building and operating production-grade LLM applications. It focuses on observability, evaluation, and collaboration to help you ship faster and more reliably.\\n\\nKey ideas\\n- Framework-agnostic: can be used with LangChain and its ecosystem, but also works with non-LangChain setups. It’s designed to be platform-agnostic.\\n- Observability: trace and gain visibility into each step of a request to debug faster.\\n- Evaluation: measure quality over time, track metrics, and compare changes as you iterate.\\n- Prompt testing and versioning: test prompts, manage prompt versions, and collaborate with your team.\\n- Collaboration and governance: set up a workspace, configure admin settings, invite teammates, and implement access controls.\\n- Self-hosting option: you can self-host LangSmith if you prefer or need to run it on your own infrastructure.\\n- SDKs and APIs: available Python and JavaScript/TypeScript SDKs (with a REST API) to instrument and interact with LangSmith from your app.\\n\\nTypical workflow\\n- Trace an application: instrument your code so LangSmith records each step of the LLM request.\\n- Evaluate and monitor: view metrics and traces to understand quality and performance over time.\\n- Test prompts: iterate on prompts with version control and collaboration features.\\n- Set up a workspace: manage users, roles, and permissions; optionally self-host.\\n\\nWho it’s for\\n- AI/ML engineers, data scientists, and product teams building production LLM apps who need reliable observability, prompt management, and debuggability.\\n\\nIf you’d like, I can:\\n- walk you through getting started (tools, code snippets, and a minimal trace example),\\n- point you to the official docs for setup and SDK usage,\\n- or help compare LangSmith with other observability tools.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"Tell me about langsmith\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "533926d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHere’s a concise primer on machine learning (ML).\n",
      "\n",
      "What it is\n",
      "- ML is a set of methods that enable computers to learn patterns from data and make predictions or decisions without being explicitly programmed for each task.\n",
      "- It’s about learning rules from examples rather than writing explicit code.\n",
      "\n",
      "Key ideas\n",
      "- Instead of hard-coding answers, you train a model on data so it can generalize to new, unseen data.\n",
      "- The quality of ML depends on data quality, the choice of model, and how well you evaluate and tune it.\n",
      "\n",
      "Main types of ML\n",
      "- Supervised learning: learn from labeled examples. Tasks include:\n",
      "  - Classification (e.g., spam detection, image type labeling)\n",
      "  - Regression (e.g., predicting house prices, weather temperatures)\n",
      "- Unsupervised learning: find structure in unlabeled data. Tasks include:\n",
      "  - Clustering (e.g., customer segmentation)\n",
      "  - Dimensionality reduction (e.g., reducing features for visualization)\n",
      "- Semi-supervised learning: uses a mix of labeled and unlabeled data.\n",
      "- Reinforcement learning: an agent learns by interacting with an environment to maximize rewards (used in robotics, game playing, some optimization problems).\n",
      "\n",
      "Common ML pipeline\n",
      "1. Define the problem and success metrics.\n",
      "2. Gather and clean data.\n",
      "3. Preprocess and feature engineer (create useful inputs for the model).\n",
      "4. Split data into training, validation, and test sets.\n",
      "5. Choose a model and train it on the training set.\n",
      "6. Evaluate on the validation set and tune hyperparameters.\n",
      "7. Test the final model on the test set and deploy.\n",
      "8. Monitor and maintain the model in production.\n",
      "\n",
      "Common algorithms and tools (high-level)\n",
      "- Simple/baseline: Linear regression, logistic regression.\n",
      "- Tree-based: Decision trees, Random forests, Gradient boosting (e.g., XGBoost, LightGBM).\n",
      "- Support Vector Machines (SVM).\n",
      "- Clustering: K-means, hierarchical clustering.\n",
      "- Dimensionality reduction: PCA, t-SNE.\n",
      "- Neural networks (deep learning): for tasks like image and speech recognition, language understanding; frameworks include TensorFlow and PyTorch.\n",
      "- Popular libraries: scikit-learn (beginner-to-intermediate), TensorFlow, PyTorch, XGBoost.\n",
      "\n",
      "How to measure success\n",
      "- Classification: accuracy, precision, recall, F1 score, ROC-AUC.\n",
      "- Regression: mean squared error (MSE), root mean squared error (RMSE), R-squared.\n",
      "- Clustering: silhouette score, Davies-Bouldin index.\n",
      "- Use a held-out test set to estimate real-world performance and avoid data leakage.\n",
      "\n",
      "Key challenges and best practices\n",
      "- Data quality and bias: biased data leads to biased models.\n",
      "- Overfitting vs underfitting: complex models may memorize data; simpler models may miss patterns.\n",
      "- Generalization: performance on training data should transfer to new data.\n",
      "- Data leakage: ensure information from the test set isn’t used in training.\n",
      "- Interpretability: some models are hard to interpret; consider simpler models or explainability tools when needed.\n",
      "- Deployment and monitoring: models can drift as data changes; monitor performance over time and update when necessary.\n",
      "\n",
      "Ethics and safety (important)\n",
      "- Be mindful of fairness, privacy, and potential harm.\n",
      "- Check for biased outcomes, disparate impact, and data privacy concerns.\n",
      "- Provide explanations where needed, especially in high-stakes decisions.\n",
      "\n",
      "Getting started\n",
      "- Pick a simple project, such as:\n",
      "  - Classifying emails as spam vs. not spam (binary classification).\n",
      "  - Predicting house prices from a few features (regression).\n",
      "  - Clustering customers by purchasing behavior (unsupervised).\n",
      "- Online courses and resources:\n",
      "  - Introductory: “Machine Learning” by Andrew Ng (Coursera), or fast.ai course.\n",
      "  - Books: \"Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow\" by Aurélien Géron, \"Pattern Recognition and Machine Learning\" by Bishop.\n",
      "- Hands-on: work with beginner-friendly datasets (e.g., Iris, Titanic, housing prices) and use libraries like scikit-learn to build simple models.\n",
      "\n",
      "If you tell me your background (e.g., programming experience, domain), your goals (quick win vs. deeper understanding), and whether you prefer a hands-on project or a theory deep dive, I can tailor a plan, example project, or a short learning path.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about machine learning',\n",
       " 'output': 'Here’s a concise primer on machine learning (ML).\\n\\nWhat it is\\n- ML is a set of methods that enable computers to learn patterns from data and make predictions or decisions without being explicitly programmed for each task.\\n- It’s about learning rules from examples rather than writing explicit code.\\n\\nKey ideas\\n- Instead of hard-coding answers, you train a model on data so it can generalize to new, unseen data.\\n- The quality of ML depends on data quality, the choice of model, and how well you evaluate and tune it.\\n\\nMain types of ML\\n- Supervised learning: learn from labeled examples. Tasks include:\\n  - Classification (e.g., spam detection, image type labeling)\\n  - Regression (e.g., predicting house prices, weather temperatures)\\n- Unsupervised learning: find structure in unlabeled data. Tasks include:\\n  - Clustering (e.g., customer segmentation)\\n  - Dimensionality reduction (e.g., reducing features for visualization)\\n- Semi-supervised learning: uses a mix of labeled and unlabeled data.\\n- Reinforcement learning: an agent learns by interacting with an environment to maximize rewards (used in robotics, game playing, some optimization problems).\\n\\nCommon ML pipeline\\n1. Define the problem and success metrics.\\n2. Gather and clean data.\\n3. Preprocess and feature engineer (create useful inputs for the model).\\n4. Split data into training, validation, and test sets.\\n5. Choose a model and train it on the training set.\\n6. Evaluate on the validation set and tune hyperparameters.\\n7. Test the final model on the test set and deploy.\\n8. Monitor and maintain the model in production.\\n\\nCommon algorithms and tools (high-level)\\n- Simple/baseline: Linear regression, logistic regression.\\n- Tree-based: Decision trees, Random forests, Gradient boosting (e.g., XGBoost, LightGBM).\\n- Support Vector Machines (SVM).\\n- Clustering: K-means, hierarchical clustering.\\n- Dimensionality reduction: PCA, t-SNE.\\n- Neural networks (deep learning): for tasks like image and speech recognition, language understanding; frameworks include TensorFlow and PyTorch.\\n- Popular libraries: scikit-learn (beginner-to-intermediate), TensorFlow, PyTorch, XGBoost.\\n\\nHow to measure success\\n- Classification: accuracy, precision, recall, F1 score, ROC-AUC.\\n- Regression: mean squared error (MSE), root mean squared error (RMSE), R-squared.\\n- Clustering: silhouette score, Davies-Bouldin index.\\n- Use a held-out test set to estimate real-world performance and avoid data leakage.\\n\\nKey challenges and best practices\\n- Data quality and bias: biased data leads to biased models.\\n- Overfitting vs underfitting: complex models may memorize data; simpler models may miss patterns.\\n- Generalization: performance on training data should transfer to new data.\\n- Data leakage: ensure information from the test set isn’t used in training.\\n- Interpretability: some models are hard to interpret; consider simpler models or explainability tools when needed.\\n- Deployment and monitoring: models can drift as data changes; monitor performance over time and update when necessary.\\n\\nEthics and safety (important)\\n- Be mindful of fairness, privacy, and potential harm.\\n- Check for biased outcomes, disparate impact, and data privacy concerns.\\n- Provide explanations where needed, especially in high-stakes decisions.\\n\\nGetting started\\n- Pick a simple project, such as:\\n  - Classifying emails as spam vs. not spam (binary classification).\\n  - Predicting house prices from a few features (regression).\\n  - Clustering customers by purchasing behavior (unsupervised).\\n- Online courses and resources:\\n  - Introductory: “Machine Learning” by Andrew Ng (Coursera), or fast.ai course.\\n  - Books: \"Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow\" by Aurélien Géron, \"Pattern Recognition and Machine Learning\" by Bishop.\\n- Hands-on: work with beginner-friendly datasets (e.g., Iris, Titanic, housing prices) and use libraries like scikit-learn to build simple models.\\n\\nIf you tell me your background (e.g., programming experience, domain), your goals (quick win vs. deeper understanding), and whether you prefer a hands-on project or a theory deep dive, I can tailor a plan, example project, or a short learning path.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"Tell me about machine learning\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff85ed11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env (3.11.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
